tokenizer error: Too many nested parentheses
 --> tests/tokens/errors/paren1.py:1:202
  |
1 | -(((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((1)))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))
  |                                                                                                                                                                                                          ^ 


Note: Please report unclear or confusing messages as bugs at
https://github.com/lcompilers/lpython/issues.
